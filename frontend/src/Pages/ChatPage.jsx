import React, { useState, useEffect, useRef, useCallback } from "react";
import { ChatMessage } from "@/entities/ChatMessage";
import { InvokeLLM } from "@/integrations/Core";
import ChatMessageComponent from "../Components/chat/ChatMessage";
import ChatInput from "../Components/chat/ChatInput";
import ChatHeader from "../Components/chat/ChatHeader";
import { Loader2 } from "lucide-react";
import { useNavigate } from "react-router-dom";

export default function ChatPage({ initialMessage = "" }) {
  const navigate = useNavigate();
  const [messages, setMessages] = useState([]);
  const [isLoading, setIsLoading] = useState(false);
  const [selectedModel, setSelectedModel] = useState("general");
  const [conversationId, setConversationId] = useState(generateConversationId());
  const [streamingMessageId, setStreamingMessageId] = useState(null); // æ–°å¢žï¼šè·Ÿè¸ªæµå¼æ¶ˆæ¯
  const messagesEndRef = useRef(null);
  const [isInitialLoad, setIsInitialLoad] = useState(true);
  const hasAutoSent = useRef(false);

  function generateConversationId() {
    return `conv_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  const loadMessages = useCallback(async () => {
    setIsInitialLoad(true);
    const loadedMessages = await ChatMessage.filter(
      { conversation_id: conversationId },
      "created_date",
      100
    );
    setMessages(loadedMessages);
    setIsInitialLoad(false);
  }, [conversationId]);

  useEffect(() => {
    loadMessages();
  }, [loadMessages]);

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

const handleStreamResponse = async (content, modelType) => {
  try {
    console.log('ðŸš€ Start requesting...');
    
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        prompt: content,
        model: modelType,
      }),
    });

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    // åˆ›å»ºåˆå§‹æ¶ˆæ¯
    const initialMessage = {
      content: '',
      role: 'assistant',
      conversation_id: conversationId,
      model: modelType,
    };

    console.log('ðŸ“ Creating initial message...');
    const savedMessage = await ChatMessage.create(initialMessage);
    setStreamingMessageId(savedMessage.id);
    setMessages(prev => [...prev, savedMessage]);

    let accumulatedContent = '';
    let buffer = '';
    let streamCompleted = false; // æ–°å¢žï¼šæ ‡è®°æµæ˜¯å¦æ­£å¸¸å®Œæˆ

    try {
      while (true) {
        const { done, value } = await reader.read();
        
        if (done) {
          console.log('âœ… Stream completed successfully');
          streamCompleted = true;
          break;
        }

        // è§£ç æ•°æ®
        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            try {
              const dataStr = line.slice(6).trim();
              if (!dataStr) continue;
              
              const data = JSON.parse(dataStr);
              console.log('ðŸ“¨ Receive Data:', data);

              if (data.error) {
                console.error('âŒ Stream error:', data.error);
                throw new Error(data.error); // æŠ›å‡ºé”™è¯¯è®©å¤–å±‚catchå¤„ç†
              }

              if (data.content) {
                accumulatedContent += data.content;
                console.log('ðŸ“ Accumulated content:', accumulatedContent);
                
                // æ›´æ–°UI
                setMessages(prev => prev.map(msg => 
                  msg.id === savedMessage.id 
                    ? { ...msg, content: accumulatedContent }
                    : msg
                ));
              }

              if (data.done) {
                console.log('ðŸŽ¯ Receive done signal, stream transmission ended');
                streamCompleted = true;
                
                // ç«‹å³æ›´æ–°æ•°æ®åº“å¹¶è¿”å›ž
                try {
                  await ChatMessage.update(savedMessage.id, { 
                    content: accumulatedContent 
                  });
                  console.log('ðŸ’¾ Database updated successfully');
                } catch (dbError) {
                  console.error('âŒ Database update failed:', dbError);
                  // æ•°æ®åº“é”™è¯¯ä¸å½±å“å‰ç«¯æ˜¾ç¤ºï¼Œåªæ˜¯ä¸æŒä¹…åŒ–
                }
                
                setStreamingMessageId(null);
                return; // ç›´æŽ¥è¿”å›žï¼Œä¸ç»§ç»­å¾ªçŽ¯
              }
            } catch (e) {
              console.warn('âš ï¸ Warning:', e, 'Data:', line);
            }
          }
        }
      }

      // å¦‚æžœå¾ªçŽ¯æ­£å¸¸ç»“æŸï¼ˆæ²¡æœ‰æ”¶åˆ°doneæ ‡è®°ï¼‰ï¼Œç¡®ä¿æ›´æ–°æ•°æ®åº“
      if (streamCompleted && accumulatedContent) {
        try {
          await ChatMessage.update(savedMessage.id, { 
            content: accumulatedContent 
          });
          console.log('ðŸ’¾ Database updated successfully');
        } catch (dbError) {
          console.error('âŒ Database update failed:', dbError);
        }
      }

    } catch (innerError) {
      console.error('âŒ Stream reading internal error:', innerError);
      throw innerError; // é‡æ–°æŠ›å‡ºè®©å¤–å±‚catchå¤„ç†
    } finally {
      setStreamingMessageId(null);
    }

  } catch (error) {
    console.error('âŒ Stream processing external error:', error);
    setStreamingMessageId(null);
    
    // åªæœ‰çœŸæ­£çš„ç½‘ç»œé”™è¯¯æ‰æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
    if (error.message.includes('HTTP error') || error.message.includes('Failed to fetch')) {
      const errorMessage = {
        content: "I apologize, but there was a network error while receiving the response. Please try again.",
        role: "assistant",
        conversation_id: conversationId,
        model: modelType,
      };
      const savedErrorMessage = await ChatMessage.create(errorMessage);
      setMessages(prev => [...prev, savedErrorMessage]);
    } else {
      // å…¶ä»–é”™è¯¯ï¼ˆå¦‚APIé”™è¯¯ï¼‰å·²ç»åœ¨æµå¼å¤„ç†ä¸­æ˜¾ç¤ºäº†ï¼Œä¸éœ€è¦é‡å¤æ˜¾ç¤º
      console.log('âš ï¸ Non-network error, already handled in streaming process');
    }
  }
};


  const handleSend = async (content) => {
    if (!content.trim()) return;

    const userMessage = {
      content,
      role: "user",
      conversation_id: conversationId,
      model: selectedModel,
    };

    const savedUserMessage = await ChatMessage.create(userMessage);
    setMessages((prev) => [...prev, savedUserMessage]);

    setIsLoading(true);

    try {
      // ä½¿ç”¨æµå¼æŽ¥å£æ›¿ä»£åŽŸæ¥çš„ InvokeLLM
      await handleStreamResponse(content, selectedModel);
    } catch (error) {
      console.error("Error getting AI response:", error);
      const errorMessage = {
        content: "I apologize, but I encountered an error. Please try again.",
        role: "assistant",
        conversation_id: conversationId,
        model: selectedModel,
      };
      const savedErrorMessage = await ChatMessage.create(errorMessage);
      setMessages(prev => [...prev, savedErrorMessage]);
    } finally {
      setIsLoading(false);
      setStreamingMessageId(null);
    }
  };

  const handleBackToHome = () => {
    navigate('/');
  };

  const handleNewChat = () => {
    setConversationId(generateConversationId());
    setMessages([]);
    setStreamingMessageId(null);
    hasAutoSent.current = false;
  };

  // 20251013ï¼šä¿®æ”¹å†…å®¹ï¼Œè‡ªåŠ¨å‘é€é¦–é¡µä¿¡æ¯
  useEffect(() => {
    if (messages.length === 0 && !hasAutoSent.current) {
      const autoSendMessage = sessionStorage.getItem('autoSendMessage');
      
      if (autoSendMessage) {
        hasAutoSent.current = true;
        console.log('Auto-sending message from homepage:', autoSendMessage);
        sessionStorage.removeItem('autoSendMessage');
        
        setTimeout(() => {
          handleSend(autoSendMessage);
        }, 100);
      }
      else if (initialMessage) {
        hasAutoSent.current = true;
        console.log('Auto-sending initial message:', initialMessage);
        
        setTimeout(() => {
          handleSend(initialMessage);
        }, 100);
      }
    }
  }, [messages.length, initialMessage]);

  return (
    <div className="flex flex-col h-screen bg-gradient-to-br from-purple-50 via-blue-50 to-indigo-50">
      <ChatHeader
        selectedModel={selectedModel}
        onNewChat={handleNewChat}
        onBackToHome={handleBackToHome}
        messageCount={messages.length}
      />

      <div className="flex-1 overflow-y-auto px-4 py-6">
        <div className="max-w-4xl mx-auto">
          {isInitialLoad ? (
            <div className="flex items-center justify-center h-64">
              <Loader2 className="w-8 h-8 animate-spin text-purple-600" />
            </div>
          ) : messages.length === 0 ? (
            <div className="flex flex-col items-center justify-center h-64 text-center">
              <div className="w-20 h-20 rounded-full bg-gradient-to-br from-purple-100 to-blue-100 flex items-center justify-center mb-6">
                <Loader2 className="w-10 h-10 text-purple-600" />
              </div>
              <h2 className="text-2xl font-bold text-gray-800 mb-3">
                Start a Conversation
              </h2>
              <p className="text-gray-500 max-w-md">
                Choose an AI model and type your message below to begin chatting.
                Your conversation will be saved automatically.
              </p>
            </div>
          ) : (
            <>
              {messages.map((message, index) => (
                <ChatMessageComponent
                  key={message.id}
                  message={message}
                  isLatest={index === messages.length - 1}
                  isStreaming={message.id === streamingMessageId} // ä¼ é€’æµå¼çŠ¶æ€
                />
              ))}
              {isLoading && !streamingMessageId && (
                <div className="flex gap-4 mb-6">
                  <div className="flex-shrink-0 w-10 h-10 rounded-full bg-gradient-to-br from-purple-500 to-blue-600 flex items-center justify-center shadow-lg">
                    <Loader2 className="w-5 h-5 text-white animate-spin" />
                  </div>
                  <div className="bg-white/90 backdrop-blur-sm rounded-2xl px-5 py-4 shadow-lg border border-gray-100">
                    <div className="flex gap-2">
                      <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: "0ms" }} />
                      <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: "150ms" }} />
                      <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: "300ms" }} />
                    </div>
                  </div>
                </div>
              )}
            </>
          )}
          <div ref={messagesEndRef} />
        </div>
      </div>

      <ChatInput
        onSend={handleSend}
        isLoading={isLoading}
        selectedModel={selectedModel}
        onModelChange={setSelectedModel}
      />
    </div>
  );
}